{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "#from tensorflow.keras import layers\n",
    "from tensorflow.compat.v1.keras import layers\n",
    "#from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.compat.v1.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_NAMES = ['train-easy/']\n",
    "FILE_NAMES = ['algebra__linear_1d.txt']\n",
    "\n",
    "BUFFER_SIZE = 50000\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "dataset_dir = parent_dir + '/Dataset'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on https://www.tensorflow.org/tutorials/load_data/text\n",
    "# Read in all files which are in FILE_NAMES\n",
    "labeled_data_sets = []\n",
    "\n",
    "for file_name in FILE_NAMES:\n",
    "    for dir_name in DIR_NAMES:\n",
    "        concat_dir = os.path.join(dir_name, file_name)\n",
    "        lines_dataset = tf.data.TextLineDataset(\n",
    "            os.path.join(dataset_dir, concat_dir)\n",
    "        )\n",
    "        labeled_data_sets.append(lines_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all File Data to one Big File Data\n",
    "all_labeled_data = labeled_data_sets[0]\n",
    "for labeled_dataset in labeled_data_sets[1:]:\n",
    "    all_labeled_data = all_labeled_data.concatenate(labeled_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group Data as batches of two (input_sentence, answer)\n",
    "all_labeled_data = all_labeled_data.batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the Data\n",
    "all_labeled_data = all_labeled_data.shuffle(\n",
    "        BUFFER_SIZE,\n",
    "        reshuffle_each_iteration=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([b'Solve 0 = 8*q + 52 - 20 for q.' b'-4'], shape=(2,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(all_labeled_data))\n",
    "print(next(iter(all_labeled_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'Solve 0 = 8*q + 52 - 20 for q.', shape=(), dtype=string)\n",
      "tf.Tensor(b'-4', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'': 0, ' ': 1, 'a': 2, 'b': 3, 'c': 4, 'd': 5, 'e': 6, 'f': 7, 'g': 8, 'h': 9, 'i': 10, 'j': 11, 'k': 12, 'l': 13, 'm': 14, 'n': 15, 'o': 16, 'p': 17, 'q': 18, 'r': 19, 's': 20, 't': 21, 'u': 22, 'v': 23, 'w': 24, 'x': 25, 'y': 26, 'z': 27, 'A': 28, 'B': 29, 'C': 30, 'D': 31, 'E': 32, 'F': 33, 'G': 34, 'H': 35, 'I': 36, 'J': 37, 'K': 38, 'L': 39, 'M': 40, 'N': 41, 'O': 42, 'P': 43, 'Q': 44, 'R': 45, 'S': 46, 'T': 47, 'U': 48, 'V': 49, 'W': 50, 'X': 51, 'Y': 52, 'Z': 53, '0': 54, '1': 55, '2': 56, '3': 57, '4': 58, '5': 59, '6': 60, '7': 61, '8': 62, '9': 63, '!': 64, '\"': 65, '#': 66, '$': 67, '%': 68, '&': 69, \"'\": 70, '(': 71, ')': 72, '*': 73, '+': 74, ',': 75, '-': 76, '.': 77, '/': 78, ':': 79, ';': 80, '<': 81, '=': 82, '>': 83, '?': 84, '@': 85, '[': 86, '\\\\': 87, ']': 88, '^': 89, '_': 90, '`': 91, '{': 92, '|': 93, '}': 94, '~': 95}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Same Code as in Data Generation\n",
    "MAX_QUESTION_LENGTH = 160\n",
    "MAX_ANSWER_LENGTH = 30\n",
    "LSTM_LENGTH = 250\n",
    "QUESTION_CHARS = ( ['', ' '] + list(string.ascii_letters + string.digits + string.punctuation))\n",
    "CHAR_TO_INDEX = {char: index for index, char in enumerate(QUESTION_CHARS)}\n",
    "INDEX_TO_CHAR = {index: char for index, char in enumerate(QUESTION_CHARS)}\n",
    "\n",
    "NUM_INDICES = len(QUESTION_CHARS)\n",
    "\n",
    "print(CHAR_TO_INDEX)\n",
    "\n",
    "keras.utils.to_categorical(0, num_classes=NUM_INDICES, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_encode_data(x):\n",
    "    x_one_hot = tf.py_function(encode_data, inp=[x[0]], Tout=(tf.float32))\n",
    "    y_one_hot = tf.py_function(encode_data, inp=[x[1]], Tout=(tf.float32))\n",
    "    \n",
    "    x_one_hot = tf.py_function(input_padding, inp=[x_one_hot, y_one_hot, LSTM_LENGTH], Tout=(tf.float32))\n",
    "    y_one_hot = tf.py_function(output_padding, inp=[y_one_hot, MAX_ANSWER_LENGTH, LSTM_LENGTH], Tout=(tf.float32))\n",
    "    \n",
    "    x_one_hot.set_shape([LSTM_LENGTH,NUM_INDICES])\n",
    "    y_one_hot.set_shape([LSTM_LENGTH,NUM_INDICES])\n",
    "    \n",
    "    return x_one_hot, y_one_hot\n",
    "    \n",
    "\n",
    "def encode_data(x):\n",
    "    x_encoded = [CHAR_TO_INDEX[z] for z in x.numpy().decode('utf-8')]\n",
    "    x_one_hot = keras.utils.to_categorical(x_encoded, num_classes=NUM_INDICES, dtype='float32')\n",
    "    \n",
    "    return x_one_hot\n",
    "\n",
    "def input_padding(tensor, out_tensor, desired_dimension):   \n",
    "    # Right pad tensor with zeros and out_tensor shifted by right to desired Dimension\n",
    "    \n",
    "    current_rows, current_cols = tf.shape(tensor)\n",
    "    current_rows_out, current_cols_out = tf.shape(out_tensor)\n",
    "    padding = tf.zeros([desired_dimension - current_rows -current_rows_out + 1, current_cols], dtype = tensor.dtype)\n",
    "    tensor = tf.concat([tensor,padding,out_tensor[:-1]], 0)\n",
    "    return tensor\n",
    "\n",
    "def output_padding(tensor, output_dimension, desired_dimension):   # Right pad tensor with zeros to desired Dimension\n",
    "    current_rows, current_cols = tf.shape(tensor)\n",
    "    if(current_rows - output_dimension != 0):\n",
    "        padding_right = tf.zeros([output_dimension - current_rows, NUM_INDICES-1], dtype = tensor.dtype)\n",
    "        padding = tf.zeros([desired_dimension - output_dimension, NUM_INDICES-1], dtype = tensor.dtype)\n",
    "        padding_right_ones = tf.ones([output_dimension - current_rows, 1], dtype = tensor.dtype)\n",
    "        padding_ones = tf.ones([desired_dimension - output_dimension, 1], dtype = tensor.dtype)\n",
    "        \n",
    "        padding = tf.concat([padding_ones, padding], 1)\n",
    "        padding_right = tf.concat([padding_right_ones, padding_right], 1)\n",
    "        \n",
    "        tensor = tf.concat([padding,tensor,padding_right], 0)\n",
    "    else:\n",
    "        padding = tf.zeros([desired_dimension - output_dimension, NUM_INDICES-1], dtype=tensor.dtype)\n",
    "        padding_ones = tf.ones([desired_dimension - output_dimension, 1], dtype = tensor.dtype)\n",
    "        padding = tf.concat([padding_ones, padding], 1)\n",
    "        tensor = tf.concat([padding,tensor], 0)\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labeled_data = all_labeled_data.map(lambda x: map_encode_data(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "TAKE_SIZE = 5000\n",
    "TAKE_TRAIN_SIZE = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 250, 96), (None, 250, 96)), types: (tf.float32, tf.float32)>\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 250, 250)          347000    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 250, 96)           24096     \n",
      "=================================================================\n",
      "Total params: 371,096\n",
      "Trainable params: 371,096\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Epoch 1/3\n"
     ]
    }
   ],
   "source": [
    "#Split in Train and Test Data (Remove .take(TAKE_SIZE) at train_data to train on all data)\n",
    "\n",
    "train_data = all_labeled_data.skip(TAKE_SIZE).take(TAKE_TRAIN_SIZE)\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "\n",
    "test_data = all_labeled_data.take(TAKE_SIZE)\n",
    "test_data = test_data.batch(BATCH_SIZE)\n",
    "\n",
    "print(train_data)\n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(layers.Input(shape=(LSTM_LENGTH,NUM_INDICES)))\n",
    "model.add(layers.LSTM(LSTM_LENGTH, return_sequences=True))\n",
    "model.add(layers.Dense(NUM_INDICES))\n",
    "print(model.summary())\n",
    "\n",
    "optimizer = Adam(\n",
    "    lr=6e-4,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.995,\n",
    "    epsilon=1e-9,\n",
    "    decay=0.0,\n",
    "    amsgrad=False,\n",
    "    clipnorm=0.1,\n",
    ")\n",
    "\n",
    "#model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\",from_logits=True, metrics=[exact])\n",
    "model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\",from_logits=True)\n",
    "\n",
    "checkpoint_path = \"./checkpoints/cp-{epoch:04d}.ckpt\"\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    period=1)\n",
    "\n",
    "model.fit(train_data,\n",
    "          validation_data=test_data,\n",
    "          epochs=3,\n",
    "          callbacks=[cp_callback],\n",
    "          verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
